{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4657769,"sourceId":7925316,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install openai\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport spacy \nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nimport openai\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-03-24T01:18:32.102843Z","iopub.execute_input":"2024-03-24T01:18:32.103207Z","iopub.status.idle":"2024-03-24T01:18:45.874949Z","shell.execute_reply.started":"2024-03-24T01:18:32.103177Z","shell.execute_reply":"2024-03-24T01:18:45.874073Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-1.14.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\nDownloading openai-1.14.2-py3-none-any.whl (262 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai\nSuccessfully installed openai-1.14.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('spam.csv')\nnlp=spacy.load('en_core_web_lg')\n# Split into labeled and unlabeled data\nlabeled_data = data.iloc[0:998]\nunlabeled_data = data.iloc[998:]\n\n# Get features and target from labeled data\nX_labeled = labeled_data['Message'].apply\ny = labeled_data['Category'].map({'spam': 1, 'ham': 0})\n\n\nlabeled_data['vector_text_embeddings'] = labeled_data['Message'].apply(lambda x: nlp(x).vector)\nlabeled_data['encoded_categories ']=y\nunlabeled_data['vector_text_embeddings'] = unlabeled_data['Message'].apply(lambda x: nlp(x).vector)","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:44:59.664450Z","iopub.status.busy":"2024-03-23T23:44:59.664065Z","iopub.status.idle":"2024-03-23T23:45:51.880958Z","shell.execute_reply":"2024-03-23T23:45:51.877797Z","shell.execute_reply.started":"2024-03-23T23:44:59.664422Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_1380/2401991888.py:12: SettingWithCopyWarning: \n\nA value is trying to be set on a copy of a slice from a DataFrame.\n\nTry using .loc[row_indexer,col_indexer] = value instead\n\n\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  labeled_data['vector_text_embeddings'] = labeled_data['Message'].apply(lambda x: nlp(x).vector)\n\n/tmp/ipykernel_1380/2401991888.py:13: SettingWithCopyWarning: \n\nA value is trying to be set on a copy of a slice from a DataFrame.\n\nTry using .loc[row_indexer,col_indexer] = value instead\n\n\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  labeled_data['encoded_categories ']=y\n\n/tmp/ipykernel_1380/2401991888.py:14: SettingWithCopyWarning: \n\nA value is trying to be set on a copy of a slice from a DataFrame.\n\nTry using .loc[row_indexer,col_indexer] = value instead\n\n\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  unlabeled_data['vector_text_embeddings'] = unlabeled_data['Message'].apply(lambda x: nlp(x).vector)\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":["numpy.int64"]},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:46:35.629586Z","iopub.status.busy":"2024-03-23T23:46:35.628883Z","iopub.status.idle":"2024-03-23T23:46:35.641848Z","shell.execute_reply":"2024-03-23T23:46:35.640822Z","shell.execute_reply.started":"2024-03-23T23:46:35.629552Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>NaN</td>\n","      <td>This is the 2nd time we have tried 2 contact u...</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>NaN</td>\n","      <td>Will ü b going to esplanade fr home?</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>NaN</td>\n","      <td>Pity, * was in mood for that. So...any other s...</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>NaN</td>\n","      <td>The guy did some bitching but I acted like i'd...</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>NaN</td>\n","      <td>Rofl. Its true to its name</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows × 2 columns</p>\n","</div>"],"text/plain":["     Category                                            Message\n","0         ham  Go until jurong point, crazy.. Available only ...\n","1         ham                      Ok lar... Joking wif u oni...\n","2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3         ham  U dun say so early hor... U c already then say...\n","4         ham  Nah I don't think he goes to usf, he lives aro...\n","...       ...                                                ...\n","5567      NaN  This is the 2nd time we have tried 2 contact u...\n","5568      NaN               Will ü b going to esplanade fr home?\n","5569      NaN  Pity, * was in mood for that. So...any other s...\n","5570      NaN  The guy did some bitching but I acted like i'd...\n","5571      NaN                         Rofl. Its true to its name\n","\n","[5572 rows x 2 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"preprocessed_labeled_data=labeled_data.drop(columns=['Message','Category'])\nunlabeled_data=unlabeled_data.drop(columns='Category')\npreprocessed_unlabeled_data=unlabeled_data.drop(columns='Message')\n\n# preprocessed_unlabeled_data   ,   preprocessed_unlabeled_data","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:47:18.591377Z","iopub.status.busy":"2024-03-23T23:47:18.590826Z","iopub.status.idle":"2024-03-23T23:47:18.596119Z","shell.execute_reply":"2024-03-23T23:47:18.594912Z","shell.execute_reply.started":"2024-03-23T23:47:18.591335Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"preprocessed_unlabeled_data","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:57:00.206796Z","iopub.status.busy":"2024-03-23T23:57:00.205809Z","iopub.status.idle":"2024-03-23T23:57:00.255584Z","shell.execute_reply":"2024-03-23T23:57:00.254326Z","shell.execute_reply.started":"2024-03-23T23:57:00.206758Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>vector_text_embeddings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>998</th>\n","      <td>[0.024603136, 0.8364921, -3.8221693, -1.203104...</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>[0.2151042, 1.1250641, -2.1523623, -0.6932293,...</td>\n","    </tr>\n","    <tr>\n","      <th>1000</th>\n","      <td>[0.18139547, 2.073278, -2.9943156, 0.33593443,...</td>\n","    </tr>\n","    <tr>\n","      <th>1001</th>\n","      <td>[1.3570703, -1.0546157, 0.3756528, -1.7727915,...</td>\n","    </tr>\n","    <tr>\n","      <th>1002</th>\n","      <td>[-1.5464095, -1.1529462, -4.769407, -0.2784880...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>[-1.1125491, -0.28742734, -1.3039072, 0.625423...</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>[-1.3827443, 4.3848166, -2.7198246, -1.683979,...</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>[-1.4874302, -0.14814456, -2.4567807, -1.36188...</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>[-1.459938, 1.7489644, -2.9308975, -1.8730268,...</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>[-1.105647, 3.4476943, -1.3477714, -2.1525986,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4574 rows × 1 columns</p>\n","</div>"],"text/plain":["                                 vector_text_embeddings\n","998   [0.024603136, 0.8364921, -3.8221693, -1.203104...\n","999   [0.2151042, 1.1250641, -2.1523623, -0.6932293,...\n","1000  [0.18139547, 2.073278, -2.9943156, 0.33593443,...\n","1001  [1.3570703, -1.0546157, 0.3756528, -1.7727915,...\n","1002  [-1.5464095, -1.1529462, -4.769407, -0.2784880...\n","...                                                 ...\n","5567  [-1.1125491, -0.28742734, -1.3039072, 0.625423...\n","5568  [-1.3827443, 4.3848166, -2.7198246, -1.683979,...\n","5569  [-1.4874302, -0.14814456, -2.4567807, -1.36188...\n","5570  [-1.459938, 1.7489644, -2.9308975, -1.8730268,...\n","5571  [-1.105647, 3.4476943, -1.3477714, -2.1525986,...\n","\n","[4574 rows x 1 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"preprocessed_labeled_data","metadata":{},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>vector_text_embeddings</th>\n","      <th>encoded_categories</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[0.8000099, 0.9535963, -0.34847602, -0.3791346...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[0.16232497, 0.8551012, -0.7290775, -0.6373049...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[-0.739487, 0.5289012, -0.13894223, -0.0169310...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[-1.8170546, 2.02302, 1.0373635, -1.0052722, 1...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[0.18221398, 4.2482843, -3.2048604, -1.1110712...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>993</th>\n","      <td>[-0.020868994, 2.1632397, -2.1657276, -0.40086...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>[-0.82344604, -0.58077604, -0.6082039, -1.4473...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>[1.249651, 4.8195105, -5.2779827, -4.001254, -...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>[1.564021, 5.1419215, -1.5199825, -1.1097636, ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>[0.31575686, 2.900634, -3.7667325, -1.502336, ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>998 rows × 2 columns</p>\n","</div>"],"text/plain":["                                vector_text_embeddings  encoded_categories \n","0    [0.8000099, 0.9535963, -0.34847602, -0.3791346...                    0\n","1    [0.16232497, 0.8551012, -0.7290775, -0.6373049...                    0\n","2    [-0.739487, 0.5289012, -0.13894223, -0.0169310...                    1\n","3    [-1.8170546, 2.02302, 1.0373635, -1.0052722, 1...                    0\n","4    [0.18221398, 4.2482843, -3.2048604, -1.1110712...                    0\n","..                                                 ...                  ...\n","993  [-0.020868994, 2.1632397, -2.1657276, -0.40086...                    0\n","994  [-0.82344604, -0.58077604, -0.6082039, -1.4473...                    0\n","995  [1.249651, 4.8195105, -5.2779827, -4.001254, -...                    0\n","996  [1.564021, 5.1419215, -1.5199825, -1.1097636, ...                    0\n","997  [0.31575686, 2.900634, -3.7667325, -1.502336, ...                    0\n","\n","[998 rows x 2 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"class_options=['spam','ham']","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:48:15.507138Z","iopub.status.busy":"2024-03-23T23:48:15.505900Z","iopub.status.idle":"2024-03-23T23:48:15.511849Z","shell.execute_reply":"2024-03-23T23:48:15.510638Z","shell.execute_reply.started":"2024-03-23T23:48:15.507091Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"openai.api_key = \"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\"  \n\ndef langchain_labeler_oracle(data_point, label_options):\n\n    prompt = f\"Please label the following data point with one of the options: {', '.join(label_options)} \\n {data_point}\"\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        max_tokens=1,\n        temperature=0.0,\n        n=1,\n        stop=None,\n        log_level=\"info\"\n    )\n\n    label = response.choices[0].text.strip()\n    if label in label_options:\n        return label_options.index(label)\n    else:\n        return None\n\n\n\n","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:48:28.431684Z","iopub.status.busy":"2024-03-23T23:48:28.430963Z","iopub.status.idle":"2024-03-23T23:48:28.438499Z","shell.execute_reply":"2024-03-23T23:48:28.437360Z","shell.execute_reply.started":"2024-03-23T23:48:28.431648Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"preprocessed_labeled_data","metadata":{},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>vector_text_embeddings</th>\n","      <th>encoded_categories</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[0.8000099, 0.9535963, -0.34847602, -0.3791346...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[0.16232497, 0.8551012, -0.7290775, -0.6373049...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[-0.739487, 0.5289012, -0.13894223, -0.0169310...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[-1.8170546, 2.02302, 1.0373635, -1.0052722, 1...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[0.18221398, 4.2482843, -3.2048604, -1.1110712...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>993</th>\n","      <td>[-0.020868994, 2.1632397, -2.1657276, -0.40086...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>[-0.82344604, -0.58077604, -0.6082039, -1.4473...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>[1.249651, 4.8195105, -5.2779827, -4.001254, -...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>[1.564021, 5.1419215, -1.5199825, -1.1097636, ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>[0.31575686, 2.900634, -3.7667325, -1.502336, ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>998 rows × 2 columns</p>\n","</div>"],"text/plain":["                                vector_text_embeddings  encoded_categories \n","0    [0.8000099, 0.9535963, -0.34847602, -0.3791346...                    0\n","1    [0.16232497, 0.8551012, -0.7290775, -0.6373049...                    0\n","2    [-0.739487, 0.5289012, -0.13894223, -0.0169310...                    1\n","3    [-1.8170546, 2.02302, 1.0373635, -1.0052722, 1...                    0\n","4    [0.18221398, 4.2482843, -3.2048604, -1.1110712...                    0\n","..                                                 ...                  ...\n","993  [-0.020868994, 2.1632397, -2.1657276, -0.40086...                    0\n","994  [-0.82344604, -0.58077604, -0.6082039, -1.4473...                    0\n","995  [1.249651, 4.8195105, -5.2779827, -4.001254, -...                    0\n","996  [1.564021, 5.1419215, -1.5199825, -1.1097636, ...                    0\n","997  [0.31575686, 2.900634, -3.7667325, -1.502336, ...                    0\n","\n","[998 rows x 2 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"def active_learning_low_confedence_sampling(labeld_data, unlabeled_data, number_of_iterations, threshold_of_loss_to_stop):\n\n    labeled_data_copy = labeled_data.copy()\n    unlabeled_data_copy = unlabeled_data.copy()\n    loss_per_iteration_all = []\n    for i in range(number_of_iterations):\n        # Split the data into training and testing\n        X_train, X_test, y_train, y_test = train_test_split(labeled_data_copy.iloc[:, :-1], labeled_data_copy.iloc[:, -1], test_size=0.2, random_state=0)\n        clf = RandomForestClassifier(random_state=0)\n        \n        # First, perform initial training on labeled data\n\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        loss_per_iteration = 1 - accuracy_score(y_test, y_pred)\n        loss_per_iteration_all.append(loss_per_iteration)\n        \n        # Find the most uncertain point\n        most_uncertainty_point = np.argmax(1 - np.max(clf.predict_proba(np.concatenate([unlabeled_data_copy])),axis=1))\n        \n        most_uncertainty_point_label = langchain_labeler_oracle(most_uncertainty_point,class_options)\n        labeled_data_copy.append((unlabeled_data_copy[most_uncertainty_point], most_uncertainty_point_label))\n        unlabeled_data_copy.remove(unlabeled_data_copy[most_uncertainty_point])\n        \n        if i > 0 and abs(loss_per_iteration_all[i] - loss_per_iteration_all[i-1]) < threshold_of_loss_to_stop:\n            break\n    \n    return labeled_data_copy, unlabeled_data_copy ,loss_per_iteration_all ,clf #clf is trained model\n","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:48:29.397740Z","iopub.status.busy":"2024-03-23T23:48:29.397019Z","iopub.status.idle":"2024-03-23T23:48:29.407094Z","shell.execute_reply":"2024-03-23T23:48:29.406024Z","shell.execute_reply.started":"2024-03-23T23:48:29.397706Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"def active_learning_lowe_margin_sampling(labeld_data, unlabel, number_of_iterations, threshold_of_loss_to_stop):\n        \n    labeled_data_copy = labeled_data.copy()\n    unlabeled_data_copy = unlabel.copy()\n    loss_per_iteration_all = []\n    for i in range(number_of_iterations):\n        X_train, X_test, y_train, y_test = train_test_split(labeled_data_copy.iloc[:, :-1], labeled_data_copy.iloc[:, -1], test_size=0.2, random_state=0)\n        clf = RandomForestClassifier(random_state=0)\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        loss_per_iteration = 1 - accuracy_score(y_test, y_pred)\n        loss_per_iteration_all.append(loss_per_iteration)\n        \n        # Find the most uncertain point (highest margin)\n        proba = clf.predict_proba(unlabeled_data_copy)\n        sorted_proba = np.sort(proba, axis=1 ,kind='mergesort')\n        margin = sorted_proba[:,-1] - sorted_proba[:,-2] \n        most_uncertain_point = np.argmin(margin)\n\n        # Prompt the user to enter the label of the most uncertain point\n        most_uncertainty_point_label = langchain_labeler_oracle(most_uncertainty_point,class_options)\n        # Add the labeled point to the labeled data\n        labeled_data_copy.append((unlabeled_data_copy[most_uncertain_point], most_uncertainty_point_label))\n        unlabeled_data_copy = unlabeled_data_copy.drop(unlabeled_data_copy.index[most_uncertain_point])\n\n        if i > 0 and abs(loss_per_iteration_all[i] - loss_per_iteration_all[i-1]) < threshold_of_loss_to_stop:\n            break    \n    return labeled_data_copy, unlabeled_data_copy ,loss_per_iteration_all \n","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:48:30.376657Z","iopub.status.busy":"2024-03-23T23:48:30.376226Z","iopub.status.idle":"2024-03-23T23:48:30.387669Z","shell.execute_reply":"2024-03-23T23:48:30.386511Z","shell.execute_reply.started":"2024-03-23T23:48:30.376625Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"def active_learning_highest_entropy_sampling(labeled_data, unlabeled_data, number_of_iterations, threshold_of_loss_to_stop):\n\n  labeled_data_copy = labeled_data.copy()\n  unlabeled_data_copy = unlabeled_data.copy()\n  loss_per_iteration_all = []\n\n  for i in range(number_of_iterations):\n    # Split the data into training and testing\n    X_train, X_test, y_train, y_test = train_test_split(labeled_data_copy.iloc[:, :-1], labeled_data_copy.iloc[:, -1], test_size=0.2, random_state=0)\n\n    # Train the Random Forest classifier\n    clf = RandomForestClassifier(random_state=0)\n    clf.fit(X_train, y_train)\n\n    # Calculate loss on test data\n    y_pred = clf.predict(X_test)\n    loss_per_iteration = 1 - accuracy_score(y_test, y_pred)\n    loss_per_iteration_all.append(loss_per_iteration)\n\n    # Find the most uncertain point (highest entropy)\n    proba = clf.predict_proba(unlabeled_data_copy)  # Get predicted probabilities\n    entropy = 1 - np.sum(proba * np.log(proba), axis=1)  # Calculate entropy\n    most_uncertainty_point = np.argmax(entropy)  # Find data point with highest entropy\n\n    # Query the user for label\n    most_uncertainty_point_label = langchain_labeler_oracle(most_uncertainty_point,class_options)\n    labeled_data_copy.append((unlabeled_data_copy[most_uncertainty_point], most_uncertainty_point_label))\n    unlabeled_data_copy.remove(unlabeled_data_copy[most_uncertainty_point])\n\n    # Early stopping\n    if i > 0 and abs(loss_per_iteration_all[i] - loss_per_iteration_all[i-1]) < threshold_of_loss_to_stop:\n      break\n\n  return labeled_data_copy, unlabeled_data_copy,loss_per_iteration_all ,clf\n","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:48:31.110644Z","iopub.status.busy":"2024-03-23T23:48:31.110222Z","iopub.status.idle":"2024-03-23T23:48:31.120940Z","shell.execute_reply":"2024-03-23T23:48:31.119707Z","shell.execute_reply.started":"2024-03-23T23:48:31.110614Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"_,_,loss_per_iteration_all,trained_model_active_learning_low_confedence_sampling =active_learning_low_confedence_sampling(preprocessed_labeled_data,preprocessed_unlabeled_data,10,0.01)","metadata":{"trusted":true},"execution_count":75,"outputs":[{"ename":"ValueError","evalue":"could not convert string to float: 'ham'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _,_,loss_per_iteration_all,trained_model_active_learning_low_confedence_sampling \u001b[38;5;241m=\u001b[39mactive_learning_low_confedence_sampling(preprocessed_labeled_data,preprocessed_unlabeled_data,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m0.01\u001b[39m)\n","Cell \u001b[0;32mIn[72], line 13\u001b[0m, in \u001b[0;36mactive_learning_low_confedence_sampling\u001b[0;34m(labeld_data, unlabeled_data, number_of_iterations, threshold_of_loss_to_stop)\u001b[0m\n\u001b[1;32m      9\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# First, perform initial training on labeled data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     15\u001b[0m loss_per_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m accuracy_score(y_test, y_pred)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[1;32m    350\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    916\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 917\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    919\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'ham'"]}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.execute_input":"2024-03-23T23:57:24.329081Z","iopub.status.busy":"2024-03-23T23:57:24.328647Z","iopub.status.idle":"2024-03-23T23:57:24.609628Z","shell.execute_reply":"2024-03-23T23:57:24.608125Z","shell.execute_reply.started":"2024-03-23T23:57:24.329036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}